version: '3.8'

services:
  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"

  llama3-8b:
    build: ./inference_service
    container_name: inference_service_llama3_8b
    ports:
      - "8002:8000"
    environment:
      MODEL_NAME: "meta-llama/Meta-Llama-3.1-8B-Instruct"
      CACHE_DIR: /usr/models
      HF_TOKEN: ${HF_TOKEN}
    volumes:
      - /usr/models:${CACHE_DIR}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  gateway_service:
    build: ./gateway_service
    container_name: gateway_service
    ports:
      - "8001:8001"
    depends_on:
      - redis
      - llama3-8b
      - postgres
    environment:
      ADMIN_KEY: ${ADMIN_KEY}

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: dbname
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres_init:/docker-entrypoint-initdb.d

volumes:
  postgres_data:
    driver: local
